{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "refer: \n",
    "@gru 구조\n",
    "https://r2rt.com/recurrent-neural-networks-in-tensorflow-ii.html\n",
    "\n",
    "@data loading\n",
    "https://github.com/RobRomijnders/LSTM_tsc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\" #4번 DEVICES만 사용하여 다른 메모리를 낭비를 방지\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "#ipython 내에 그래프가 보이게함\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "import pandas as pd\n",
    "testdatasets = ['synthetic_control','PhalangesOutlinesCorrect', 'DistalPhalanxOutlineAgeGroup', 'DistalPhalanxOutlineCorrect', 'DistalPhalanxTW', \n",
    "                'MiddlePhalanxOutlineAgeGroup', 'MiddlePhalanxOutlineCorrect', 'MiddlePhalanxTW', 'ProximalPhalanxOutlineAgeGroup', \n",
    "                'ProximalPhalanxOutlineCorrect', 'ProximalPhalanxTW', 'ElectricDevices', 'MedicalImages', 'SwedishLeaf', 'Two_Patterns', 'ECG5000', \n",
    "                'ECGFiveDays', 'wafer', 'ChlorineConcentration', 'Adiac', 'Strawberry', 'Cricket_X', 'Cricket_Y', 'Cricket_Z', 'uWaveGestureLibrary_X', \n",
    "                'uWaveGestureLibrary_Y', 'uWaveGestureLibrary_Z', 'yoga', 'FordA', 'FordB']\n",
    "# csv :'synthetic_control',\n",
    "header = ['data_train.size','data_test.size', 'X_train.instance','X_test.instance', 'X_test.feautre', 'X_train.feautre', 'num_label', 'num_label']\n",
    "row = len(testdatasets)\n",
    "col = len(header)\n",
    "matrix = np.zeros((row,col))\n",
    "\n",
    "for i, data in enumerate(testdatasets):\n",
    "    DATA_DIR = '/home/sohee/UCR_TS_Archive_2015' + '/' + data + '/' + data\n",
    "    data_train = np.loadtxt(DATA_DIR+'_TRAIN', delimiter=',')\n",
    "    data_test = np.loadtxt(DATA_DIR+'_TEST', delimiter=',')\n",
    "\n",
    "    X_train = data_train[:,1:]\n",
    "    y_train = data_train[:,0]\n",
    "    \n",
    "    X_test = data_test[:,1:]\n",
    "    y_test = data_test[:,0]\n",
    "    \n",
    "    matrix[i][0] = data_train.size\n",
    "    matrix[i][1] = data_test.size\n",
    "    \n",
    "    matrix[i][2] = X_train.shape[0]\n",
    "    matrix[i][3] = X_test.shape[0]\n",
    "    \n",
    "    matrix[i][4] = X_train.shape[1]\n",
    "    matrix[i][5] = X_test.shape[1]\n",
    "    \n",
    "    matrix[i][6] = len(np.unique(y_train))    \n",
    "    matrix[i][7] = len(np.unique(y_test))\n",
    "    \n",
    "df=pd.DataFrame(matrix, index=testdatasets, columns=header, dtype=int)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "saver = tf.train.import_meta_graph(\"./180122_3.ckpt.meta\")\n",
    "\n",
    "learning_rate = 0.001\n",
    "total_epoch = 1000\n",
    "batch_size = 100 \n",
    "dropout = 0.5\n",
    "hidden_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Timenet:\n",
    "    \n",
    "    def __init__(self, sess, dataset):\n",
    "        print(\"===============================================================  \", dataset)\n",
    "        self.sess = sess\n",
    "        self.dataset = dataset\n",
    "        self.model(self.dataset)\n",
    "        \n",
    "    def model(self, dataset):\n",
    "        datadir = '/home/sohee/UCR_TS_Archive_2015' + '/' + dataset + '/' + dataset\n",
    "        data_train = np.loadtxt(datadir+'_TRAIN', delimiter=',')\n",
    "        data_test = np.loadtxt(datadir+'_TEST', delimiter=',')\n",
    "\n",
    "        #train data\n",
    "        self.X_train = data_train[:,1:]\n",
    "        self.y_train = data_train[:,0]\n",
    "        print(\"train data's size :\",self.X_train.shape[0])\n",
    "        y_train_first_index = int(np.unique(self.y_train)[0])\n",
    "        if int(y_train_first_index) == 1:\n",
    "            self.y_train = data_train[:,0]-1\n",
    "\n",
    "        #test data\n",
    "        self.X_test = data_test[:,1:]\n",
    "        self.y_test = data_test[:,0]\n",
    "        print(\"test data's size :\",self.y_test.shape[0])\n",
    "        y_test_first_index = int(np.unique(self.y_test)[0])\n",
    "        if int(y_test_first_index) == 1:\n",
    "            self.y_test = data_test[:,0]-1\n",
    "\n",
    "        n_variable = self.X_train.shape[1]\n",
    "        \n",
    "        # placeholder\n",
    "        self.encoder_inputs = tf.placeholder(tf.float32, [None, n_variable], name=\"encoder_inputs\") \n",
    "        self.decoder_inputs = tf.placeholder(tf.float32, [None, n_variable], name=\"decoder_inputs\")\n",
    "        self.targets = tf.placeholder(tf.int64, [None], name=\"targets\")\n",
    "\n",
    "        with tf.variable_scope(\"seq2seq\"+dataset):  \n",
    "            cell = tf.contrib.rnn.GRUCell(num_units=hidden_size)\n",
    "            outputs, states = tf.contrib.legacy_seq2seq.basic_rnn_seq2seq([self.encoder_inputs], [self.decoder_inputs], cell)\n",
    "            outputs = tf.reshape(outputs, [-1, hidden_size]) #3D -> 2D # output 모양이 항상 [? , hidden_size]으로 고정됨\n",
    "\n",
    "            #W = tf.Variable(tf.random_normal([hidden_size, 100]), name=\"W\")\n",
    "            #b = tf.Variable(tf.random_normal([100]), name=\"b\")\n",
    "            W = tf.get_default_graph().get_tensor_by_name(\"W:0\")\n",
    "            b = tf.get_default_graph().get_tensor_by_name(\"b:0\")\n",
    "            logits = tf.matmul(outputs, W) + b\n",
    "\n",
    "        with tf.variable_scope(\"cost\"+dataset):\n",
    "            self.cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=self.targets))\n",
    "            self.optimizer = tf.train.AdamOptimizer(learning_rate).minimize(self.cost) \n",
    "\n",
    "        with tf.variable_scope(\"eval\"+dataset):\n",
    "            prediction = tf.argmax(tf.nn.softmax(logits), 1) \n",
    "            correct_prediction = tf.equal(prediction, self.targets)#one-hot을 안쓰면 target에는 argmax할 필요없음\n",
    "            self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        \n",
    "    def try_optimize(self):\n",
    "        return self.sess.run([self.cost, self.optimazer2], feed_dict={ self.encoder_inputs : self.X_train, \n",
    "                                                                      self.decoder_inputs : self.X_train, \n",
    "                                                                      self.targets : self.y_train })\n",
    "    \n",
    "    def acc_calculator(self):\n",
    "        return self.sess.run( self.accuracy, feed_dict={ self.encoder_inputs : self.X_test, \n",
    "                                                        self.decoder_inputs : self.X_test, \n",
    "                                                        self.targets : self.y_test })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================   synthetic_control\n",
      "train data's size : 300\n",
      "test data's size : 300\n",
      "INFO:tensorflow:Restoring parameters from ./180122_3.ckpt\n",
      "... check point loaded\n",
      "Epoch 1/1000  cost :  5.77494\n",
      "Epoch 500/1000  cost :  0.00026516\n",
      "Epoch 1000/1000  cost :  8.32939e-05\n",
      " It took  31.070587158203125 s.\n",
      "\n",
      "synthetic_control , Accuracy: 0.85 , Error rate :  0.149999976158  with Transfer Learning \n",
      "\n",
      "===============================================================   PhalangesOutlinesCorrect\n",
      "train data's size : 1800\n",
      "test data's size : 858\n",
      "INFO:tensorflow:Restoring parameters from ./180122_3.ckpt\n",
      "... check point loaded\n",
      "Epoch 1/1000  cost :  8.9481\n",
      "Epoch 500/1000  cost :  0.479623\n",
      "Epoch 1000/1000  cost :  0.345472\n",
      " It took  141.74941492080688 s.\n",
      "\n",
      "PhalangesOutlinesCorrect , Accuracy: 0.786713 , Error rate :  0.213286697865  with Transfer Learning \n",
      "\n",
      "===============================================================   DistalPhalanxOutlineAgeGroup\n",
      "train data's size : 139\n",
      "test data's size : 400\n",
      "INFO:tensorflow:Restoring parameters from ./180122_3.ckpt\n",
      "... check point loaded\n",
      "Epoch 1/1000  cost :  6.20282\n",
      "Epoch 500/1000  cost :  0.0866238\n",
      "Epoch 1000/1000  cost :  0.0104062\n",
      " It took  18.958085536956787 s.\n",
      "\n",
      "DistalPhalanxOutlineAgeGroup , Accuracy: 0.7775 , Error rate :  0.222500026226  with Transfer Learning \n",
      "\n",
      "===============================================================   DistalPhalanxOutlineCorrect\n",
      "train data's size : 276\n",
      "test data's size : 600\n",
      "INFO:tensorflow:Restoring parameters from ./180122_3.ckpt\n",
      "... check point loaded\n",
      "Epoch 1/1000  cost :  4.94595\n",
      "Epoch 500/1000  cost :  0.111331\n",
      "Epoch 1000/1000  cost :  0.0546161\n",
      " It took  30.28710389137268 s.\n",
      "\n",
      "DistalPhalanxOutlineCorrect , Accuracy: 0.783333 , Error rate :  0.216666638851  with Transfer Learning \n",
      "\n",
      "===============================================================   DistalPhalanxTW\n",
      "train data's size : 139\n",
      "test data's size : 400\n",
      "INFO:tensorflow:Restoring parameters from ./180122_3.ckpt\n",
      "... check point loaded\n",
      "Epoch 1/1000  cost :  8.07154\n",
      "Epoch 500/1000  cost :  0.00852941\n",
      "Epoch 1000/1000  cost :  0.000886305\n",
      " It took  19.328534841537476 s.\n",
      "\n",
      "DistalPhalanxTW , Accuracy: 0.735 , Error rate :  0.264999985695  with Transfer Learning \n",
      "\n",
      "===============================================================   MiddlePhalanxOutlineAgeGroup\n",
      "train data's size : 154\n",
      "test data's size : 400\n",
      "INFO:tensorflow:Restoring parameters from ./180122_3.ckpt\n",
      "... check point loaded\n",
      "Epoch 1/1000  cost :  6.54237\n",
      "Epoch 500/1000  cost :  0.539742\n",
      "Epoch 1000/1000  cost :  0.349075\n",
      " It took  20.69322395324707 s.\n",
      "\n",
      "MiddlePhalanxOutlineAgeGroup , Accuracy: 0.74 , Error rate :  0.259999990463  with Transfer Learning \n",
      "\n",
      "===============================================================   MiddlePhalanxOutlineCorrect\n",
      "train data's size : 291\n",
      "test data's size : 600\n",
      "INFO:tensorflow:Restoring parameters from ./180122_3.ckpt\n",
      "... check point loaded\n",
      "Epoch 1/1000  cost :  5.97151\n",
      "Epoch 500/1000  cost :  0.241472\n",
      "Epoch 1000/1000  cost :  0.22686\n",
      " It took  31.953500747680664 s.\n",
      "\n",
      "MiddlePhalanxOutlineCorrect , Accuracy: 0.786667 , Error rate :  0.213333308697  with Transfer Learning \n",
      "\n",
      "===============================================================   MiddlePhalanxTW\n",
      "train data's size : 154\n",
      "test data's size : 399\n",
      "INFO:tensorflow:Restoring parameters from ./180122_3.ckpt\n",
      "... check point loaded\n",
      "Epoch 1/1000  cost :  8.07441\n",
      "Epoch 500/1000  cost :  0.465118\n",
      "Epoch 1000/1000  cost :  0.182641\n",
      " It took  20.752296686172485 s.\n",
      "\n",
      "MiddlePhalanxTW , Accuracy: 0.601504 , Error rate :  0.39849627018  with Transfer Learning \n",
      "\n",
      "===============================================================   ProximalPhalanxOutlineAgeGroup\n",
      "train data's size : 400\n",
      "test data's size : 205\n",
      "INFO:tensorflow:Restoring parameters from ./180122_3.ckpt\n",
      "... check point loaded\n",
      "Epoch 1/1000  cost :  7.21394\n",
      "Epoch 500/1000  cost :  0.241678\n",
      "Epoch 1000/1000  cost :  0.285436\n",
      " It took  40.74635052680969 s.\n",
      "\n",
      "ProximalPhalanxOutlineAgeGroup , Accuracy: 0.848781 , Error rate :  0.15121948719  with Transfer Learning \n",
      "\n",
      "===============================================================   ProximalPhalanxOutlineCorrect\n",
      "train data's size : 600\n",
      "test data's size : 291\n",
      "INFO:tensorflow:Restoring parameters from ./180122_3.ckpt\n",
      "... check point loaded\n",
      "Epoch 1/1000  cost :  5.69258\n",
      "Epoch 500/1000  cost :  0.358434\n",
      "Epoch 1000/1000  cost :  0.254272\n",
      " It took  60.34308385848999 s.\n",
      "\n",
      "ProximalPhalanxOutlineCorrect , Accuracy: 0.879725 , Error rate :  0.12027490139  with Transfer Learning \n",
      "\n",
      "===============================================================   ProximalPhalanxTW\n",
      "train data's size : 205\n",
      "test data's size : 400\n",
      "INFO:tensorflow:Restoring parameters from ./180122_3.ckpt\n",
      "... check point loaded\n",
      "Epoch 1/1000  cost :  7.89614\n",
      "Epoch 500/1000  cost :  0.19219\n",
      "Epoch 1000/1000  cost :  0.120947\n",
      " It took  28.21007013320923 s.\n",
      "\n",
      "ProximalPhalanxTW , Accuracy: 0.775 , Error rate :  0.225000023842  with Transfer Learning \n",
      "\n",
      "===============================================================   ElectricDevices\n",
      "train data's size : 8926\n",
      "test data's size : 7711\n",
      "INFO:tensorflow:Restoring parameters from ./180122_3.ckpt\n",
      "... check point loaded\n",
      "Epoch 1/1000  cost :  6.85359\n",
      "Epoch 500/1000  cost :  0.0580752\n",
      "Epoch 1000/1000  cost :  0.0255628\n",
      " It took  768.7466804981232 s.\n",
      "\n",
      "ElectricDevices , Accuracy: 0.518869 , Error rate :  0.481130838394  with Transfer Learning \n",
      "\n",
      "===============================================================   MedicalImages\n",
      "train data's size : 381\n",
      "test data's size : 760\n",
      "INFO:tensorflow:Restoring parameters from ./180122_3.ckpt\n",
      "... check point loaded\n",
      "Epoch 1/1000  cost :  8.01851\n",
      "Epoch 500/1000  cost :  0.0168218\n",
      "Epoch 1000/1000  cost :  0.000654529\n",
      " It took  47.95155739784241 s.\n",
      "\n",
      "MedicalImages , Accuracy: 0.693421 , Error rate :  0.306578934193  with Transfer Learning \n",
      "\n",
      "===============================================================   SwedishLeaf\n",
      "train data's size : 500\n",
      "test data's size : 625\n",
      "INFO:tensorflow:Restoring parameters from ./180122_3.ckpt\n",
      "... check point loaded\n",
      "Epoch 1/1000  cost :  8.17528\n",
      "Epoch 500/1000  cost :  0.00220508\n",
      "Epoch 1000/1000  cost :  0.00040028\n",
      " It took  56.32701373100281 s.\n",
      "\n",
      "SwedishLeaf , Accuracy: 0.8608 , Error rate :  0.139199972153  with Transfer Learning \n",
      "\n",
      "===============================================================   Two_Patterns\n",
      "train data's size : 1000\n",
      "test data's size : 4000\n",
      "INFO:tensorflow:Restoring parameters from ./180122_3.ckpt\n",
      "... check point loaded\n",
      "Epoch 1/1000  cost :  8.07607\n",
      "Epoch 500/1000  cost :  0.000478128\n",
      "Epoch 1000/1000  cost :  0.000145577\n",
      " It took  109.55048251152039 s.\n",
      "\n",
      "Two_Patterns , Accuracy: 0.87275 , Error rate :  0.127250015736  with Transfer Learning \n",
      "\n",
      "===============================================================   ECG5000\n",
      "train data's size : 500\n",
      "test data's size : 4500\n",
      "INFO:tensorflow:Restoring parameters from ./180122_3.ckpt\n",
      "... check point loaded\n",
      "Epoch 1/1000  cost :  6.20122\n",
      "Epoch 500/1000  cost :  0.000480983\n",
      "Epoch 1000/1000  cost :  6.38342e-05\n",
      " It took  58.96371674537659 s.\n",
      "\n",
      "ECG5000 , Accuracy: 0.928222 , Error rate :  0.0717777609825  with Transfer Learning \n",
      "\n",
      "===============================================================   ECGFiveDays\n",
      "train data's size : 23\n",
      "test data's size : 861\n",
      "INFO:tensorflow:Restoring parameters from ./180122_3.ckpt\n",
      "... check point loaded\n",
      "Epoch 1/1000  cost :  8.25926\n",
      "Epoch 500/1000  cost :  9.38359e-05\n",
      "Epoch 1000/1000  cost :  3.22209e-05\n",
      " It took  10.883020639419556 s.\n",
      "\n",
      "ECGFiveDays , Accuracy: 0.932636 , Error rate :  0.0673635601997  with Transfer Learning \n",
      "\n",
      "===============================================================   ChlorineConcentration\n",
      "train data's size : 467\n",
      "test data's size : 3840\n",
      "INFO:tensorflow:Restoring parameters from ./180122_3.ckpt\n",
      "... check point loaded\n",
      "Epoch 1/1000  cost :  9.06066\n",
      "Epoch 500/1000  cost :  0.176626\n",
      "Epoch 1000/1000  cost :  0.0732752\n",
      " It took  63.15967583656311 s.\n",
      "\n",
      "ChlorineConcentration , Accuracy: 0.813802 , Error rate :  0.186197936535  with Transfer Learning \n",
      "\n",
      "===============================================================   Adiac\n",
      "train data's size : 390\n",
      "test data's size : 391\n",
      "INFO:tensorflow:Restoring parameters from ./180122_3.ckpt\n",
      "... check point loaded\n",
      "Epoch 1/1000  cost :  8.38665\n",
      "Epoch 500/1000  cost :  0.360654\n",
      "Epoch 1000/1000  cost :  0.143094\n",
      " It took  60.06813383102417 s.\n",
      "\n",
      "Adiac , Accuracy: 0.734015 , Error rate :  0.265984654427  with Transfer Learning \n",
      "\n",
      "===============================================================   Strawberry\n",
      "train data's size : 370\n",
      "test data's size : 613\n",
      "INFO:tensorflow:Restoring parameters from ./180122_3.ckpt\n",
      "... check point loaded\n",
      "Epoch 1/1000  cost :  7.8486\n",
      "Epoch 500/1000  cost :  0.0733748\n",
      "Epoch 1000/1000  cost :  0.0667562\n",
      " It took  60.824957609176636 s.\n",
      "\n",
      "Strawberry , Accuracy: 0.955954 , Error rate :  0.0440456867218  with Transfer Learning \n",
      "\n",
      "===============================================================   Cricket_X\n",
      "train data's size : 390\n",
      "test data's size : 390\n",
      "INFO:tensorflow:Restoring parameters from ./180122_3.ckpt\n",
      "... check point loaded\n",
      "Epoch 1/1000  cost :  9.52523\n",
      "Epoch 500/1000  cost :  0.000204831\n",
      "Epoch 1000/1000  cost :  7.75386e-05\n",
      " It took  71.94574737548828 s.\n",
      "\n",
      "Cricket_X , Accuracy: 0.546154 , Error rate :  0.453846156597  with Transfer Learning \n",
      "\n",
      "===============================================================   Cricket_Y\n",
      "train data's size : 390\n",
      "test data's size : 390\n",
      "INFO:tensorflow:Restoring parameters from ./180122_3.ckpt\n",
      "... check point loaded\n",
      "Epoch 1/1000  cost :  9.07029\n",
      "Epoch 500/1000  cost :  0.000266496\n",
      "Epoch 1000/1000  cost :  9.63531e-05\n",
      " It took  70.41751837730408 s.\n",
      "\n",
      "Cricket_Y , Accuracy: 0.571795 , Error rate :  0.428205132484  with Transfer Learning \n",
      "\n",
      "===============================================================   Cricket_Z\n",
      "train data's size : 390\n",
      "test data's size : 390\n",
      "INFO:tensorflow:Restoring parameters from ./180122_3.ckpt\n",
      "... check point loaded\n",
      "Epoch 1/1000  cost :  8.7348\n",
      "Epoch 500/1000  cost :  0.000203952\n",
      "Epoch 1000/1000  cost :  7.56089e-05\n",
      " It took  65.30901026725769 s.\n",
      "\n",
      "Cricket_Z , Accuracy: 0.54359 , Error rate :  0.456410229206  with Transfer Learning \n",
      "\n",
      "===============================================================   uWaveGestureLibrary_X\n",
      "train data's size : 896\n",
      "test data's size : 3582\n",
      "INFO:tensorflow:Restoring parameters from ./180122_3.ckpt\n",
      "... check point loaded\n",
      "Epoch 1/1000  cost :  9.62907\n",
      "Epoch 500/1000  cost :  0.00172539\n",
      "Epoch 1000/1000  cost :  0.000395608\n",
      " It took  128.95748615264893 s.\n",
      "\n",
      "uWaveGestureLibrary_X , Accuracy: 0.765494 , Error rate :  0.2345058918  with Transfer Learning \n",
      "\n",
      "===============================================================   uWaveGestureLibrary_Y\n",
      "train data's size : 896\n",
      "test data's size : 3582\n",
      "INFO:tensorflow:Restoring parameters from ./180122_3.ckpt\n",
      "... check point loaded\n",
      "Epoch 1/1000  cost :  7.73456\n",
      "Epoch 500/1000  cost :  0.0035841\n",
      "Epoch 1000/1000  cost :  0.000668289\n",
      " It took  132.51481461524963 s.\n",
      "\n",
      "uWaveGestureLibrary_Y , Accuracy: 0.672529 , Error rate :  0.32747066021  with Transfer Learning \n",
      "\n",
      "===============================================================   uWaveGestureLibrary_Z\n",
      "train data's size : 896\n",
      "test data's size : 3582\n",
      "INFO:tensorflow:Restoring parameters from ./180122_3.ckpt\n",
      "... check point loaded\n",
      "Epoch 1/1000  cost :  10.0071\n",
      "Epoch 500/1000  cost :  0.00269623\n",
      "Epoch 1000/1000  cost :  0.000556287\n",
      " It took  129.7548496723175 s.\n",
      "\n",
      "uWaveGestureLibrary_Z , Accuracy: 0.6823 , Error rate :  0.317699611187  with Transfer Learning \n",
      "\n",
      "===============================================================   yoga\n",
      "train data's size : 300\n",
      "test data's size : 3000\n",
      "INFO:tensorflow:Restoring parameters from ./180122_3.ckpt\n",
      "... check point loaded\n",
      "Epoch 1/1000  cost :  11.6651\n",
      "Epoch 500/1000  cost :  0.00123572\n",
      "Epoch 1000/1000  cost :  0.000232456\n",
      " It took  66.5967071056366 s.\n",
      "\n",
      "yoga , Accuracy: 0.843 , Error rate :  0.157000005245  with Transfer Learning \n",
      "\n"
     ]
    }
   ],
   "source": [
    "testdatasets = ['synthetic_control','PhalangesOutlinesCorrect', 'DistalPhalanxOutlineAgeGroup', 'DistalPhalanxOutlineCorrect', 'DistalPhalanxTW', \n",
    "                'MiddlePhalanxOutlineAgeGroup', 'MiddlePhalanxOutlineCorrect', 'MiddlePhalanxTW', 'ProximalPhalanxOutlineAgeGroup', \n",
    "                'ProximalPhalanxOutlineCorrect', 'ProximalPhalanxTW', 'ElectricDevices', 'MedicalImages', 'SwedishLeaf', 'Two_Patterns', 'ECG5000', \n",
    "                'ECGFiveDays', 'ChlorineConcentration', 'Adiac', 'Strawberry', 'Cricket_X', 'Cricket_Y', 'Cricket_Z', 'uWaveGestureLibrary_X', \n",
    "                'uWaveGestureLibrary_Y', 'uWaveGestureLibrary_Z', 'yoga']\n",
    "\n",
    "for dataset in testdatasets :   \n",
    "    sess = tf.Session()\n",
    "    m = Timenet(sess, dataset)\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.restore(sess, \"./180122_3.ckpt\")\n",
    "    print(\"... check point loaded\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(total_epoch):\n",
    "\n",
    "        cost, _= sess.run( [m.cost, m.optimizer], feed_dict={ m.encoder_inputs : m.X_train, m.decoder_inputs : m.X_train, m.targets : m.y_train })\n",
    "        \n",
    "        if epoch == 0:  \n",
    "            print(\"Epoch {}/1000 \".format(epoch+1), \"cost : \", cost)\n",
    "        if epoch == (total_epoch//2-1) :  \n",
    "            print(\"Epoch {}/1000 \".format(epoch+1), \"cost : \", cost)\n",
    "        if epoch == (total_epoch-1) :  \n",
    "            print(\"Epoch {}/1000 \".format(epoch+1), \"cost : \", cost) \n",
    "            \n",
    "    print(\" It took \", time.time()-start_time, \"s.\")\n",
    "    \n",
    "    acc = m.acc_calculator()\n",
    "    print(\"\")\n",
    "    print(dataset, ', Accuracy:', acc, ', Error rate : ', 1-acc, \" with Transfer Learning \")\n",
    "    print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
